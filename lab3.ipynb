{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vDwtzQ-AJe6c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lif-c64pJe6h"
      },
      "outputs": [],
      "source": [
        "w1 = tf.constant([[1.4334732, -1.5244598, 1.139654, 2.723477, 2.372128, -1.8221221],\n",
        "      [1.6633688, -1.3922757, 2.0349483, 1.6314147, 1.6997916, -1.719175],\n",
        "      [1.6464833, -1.6136154, 1.6790704, 2.1913328, 1.7154503, -2.122219],\n",
        "      [2.2029521, -2.2169485, 1.1411709, 1.7363839, 1.9620435, -1.990284],\n",
        "      [1.864349, -1.9724554, 1.282788, 1.3895663, 1.2881863, -1.3681948],\n",
        "      [0.4421571, 0.24537054, 0.49080196, -0.0939824, 0.36308903, -0.32526237],\n",
        "      [-1.6102886, 1.7532632, -1.3683709, -1.2728035, -1.8335032, 1.6637068],\n",
        "      [-1.0453694, 0.95990705, -1.913037, -1.637573, -1.8312218, 1.9757035],\n",
        "      [-2.6982157, 1.5073962, -2.243781, -2.7327728, -2.5648139, 1.9095569],\n",
        "      [-2.0628226, 2.3980575, -1.3550557, -2.1798916, -2.1485612, 2.2912557]], dtype=tf.float32)\n",
        "\n",
        "w2 = tf.constant([[2.220895], [-2.903738], [1.7675139],\n",
        "      [2.3042984], [2.6292808], [-2.763858]], dtype=tf.float32)\n",
        "\n",
        "b1 = tf.constant([-1.6460503, 1.5486399, -1.5155386, -1.6247352, -1.2638505, 1.5515162], dtype=tf.float32)\n",
        "b2 = tf.constant([-1.1827456], dtype=tf.float32)\n",
        "\n",
        "x1 = tf.constant([0.85, 0.86, 0.76, 0.73, 0.95, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=tf.float32)\n",
        "x2 = tf.constant([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.67, 0.87], dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5a9LKYK7Je6i"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def neural_net(x: tf.Tensor, w1: tf.Tensor, w2: tf.Tensor, b1: tf.Tensor, b2: tf.Tensor) -> tf.Tensor:\n",
        "    tf.debugging.assert_type(x, tf_type=tf.float32)\n",
        "    hidden_layer = tf.sigmoid(tf.add(tf.matmul(tf.reshape(x, [1, -1]), w1), b1))\n",
        "    y = tf.sigmoid(tf.add(tf.matmul(hidden_layer, w2), b2))\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "bexbjm769ldr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = neural_net(x1, w1, w2, b1, b2)\n",
        "y2 = neural_net(x2, w1, w2, b1, b2)\n",
        "print(f'y1: {y1}')\n",
        "print(f'y2: {y2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTV5wpLo9klC",
        "outputId": "279c49f9-c9a1-40cf-9f1a-9a98343ebcfd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y1: [[0.9977336]]\n",
            "y2: [[0.00667112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With @tf.function annotation"
      ],
      "metadata": {
        "id": "g1esLQNY8vnn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uzo-QLeJe6j",
        "outputId": "ec6cf4b7-8e9c-432d-cbfd-7578f688b83a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time in graph mode for tensor x1: 95.6233750000024 milliseconds\n"
          ]
        }
      ],
      "source": [
        "func_y1 = timeit.timeit(lambda: neural_net(x1, w1, w2, b1, b2), number=3)\n",
        "print(f'Execution time in graph mode for tensor x1: {func_y1*1000} milliseconds')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func_y2 = timeit.timeit(lambda: neural_net(x2, w1, w2, b1, b2), number=3)\n",
        "print(f'Execution time in graph mode for tensor x2: {func_y2*1000} milliseconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JocJSawq9J_O",
        "outputId": "c4bb7f8a-1536-4106-865c-64b580d6be46"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time in graph mode for tensor x2: 100.91687799996407 milliseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without @tf.function annotation"
      ],
      "metadata": {
        "id": "dGGxxFn682H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eager_y1 = timeit.timeit(lambda: neural_net(x1, w1, w2, b1, b2), number=3)\n",
        "print(f'Execution time in eager mode for tensor x2: {eager_y1*1000} milliseconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHAsiZvq85KN",
        "outputId": "680a64fc-e30c-407f-8250-6e7d0b98d043"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time in eager mode for tensor x2: 3.1411729999604177 milliseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eager_y2 = timeit.timeit(lambda: neural_net(x2, w1, w2, b1, b2), number=3)\n",
        "print(f'Execution time in eager mode for tensor x2: {eager_y2*1000} milliseconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwSHwu248_bn",
        "outputId": "8bb06c42-fff0-4056-f359-feca0ab35806"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time in eager mode for tensor x2: 4.613655000014205 milliseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wnioski\n",
        "\n",
        "Czas odpowiedzi sieci w trybie graph mode wyniósł 95,6 ms dla pierwszego wektora oraz 100,9 ms dla drugiego wektora.\n",
        "\n",
        "Czas odpowiedzi sieci w trybie eager mode wyniósł 3,14 ms dla pierwszego wektora oraz 4,61 ms dla drugiego wektora.\n",
        "\n",
        "Znacznie dłuższy czas odpowiedzi sieci w trybie graph mode wynika z potrzeby skonstruowania grafu (tf.Graph), który przyspiesza wykonywanie operacji tensorowych m.in. poprzez ich zrównoleglenie. W przypadku kilku prostych operacji, czas potrzebny do skonstruowania grafu przewyższa czas samych obliczeń. Taka sytuacja ma miejsce jedynie przy pierwszym wywołaniu funkcji. Powyższe odpytania sieci miały każdorazowo miejsce bezpośrednio po jej deklaracji. Gdyby wywołać funkcję ponownie w trybie graph mode, czas odpowiedzi zmaleje. "
      ],
      "metadata": {
        "id": "D8I3dGQX9dba"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}