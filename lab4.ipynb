{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = tf.keras.datasets.mnist.load_data()\n",
    "trainX = tf.cast(trainX, tf.float32) / 255.\n",
    "testX = tf.cast(testX, tf.float32) / 255.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "sequential_model.summary()\n",
    "sequential_model.load_weights(\"model_w.h5\")\n",
    "sequential_model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[metrics.CategoricalAccuracy(), metrics.Precision(), metrics.Recall()])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 628us/step - loss: 0.0768 - categorical_accuracy: 0.9778 - precision: 0.9789 - recall: 0.9762\n",
      "Accuracy:  0.9778000116348267\n",
      "Precision:  0.978941023349762\n",
      "Recall:  0.9761999845504761\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy_sequential_eval, precision_sequential_eval, recall_sequential_eval) = sequential_model.evaluate(testX, tf.one_hot(testY, depth=10), verbose=1)\n",
    "print(\"Accuracy: \", accuracy_sequential_eval)\n",
    "print(\"Precision: \", precision_sequential_eval)\n",
    "print(\"Recall: \", recall_sequential_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn metrics (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 532us/step\n",
      "Accuracy:  0.9778\n",
      "Precision:  0.9778581534433096\n",
      "Recall:  0.9775777296255154\n"
     ]
    }
   ],
   "source": [
    "preds_sequential = sequential_model.predict(testX)\n",
    "accuracy_sequential = accuracy_score(testY, preds_sequential.argmax(axis=1))\n",
    "precision_sequential, recall_sequential, _, _ = precision_recall_fscore_support(\n",
    "    testY, preds_sequential.argmax(axis=1), average='macro')\n",
    "print(\"Accuracy: \", accuracy_sequential)\n",
    "print(\"Precision: \", precision_sequential)\n",
    "print(\"Recall: \", recall_sequential)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(28, 28))\n",
    "flatten = layers.Flatten()(inputs)\n",
    "dense1 = layers.Dense(128, activation=\"relu\")(flatten)\n",
    "dense2 = layers.Dense(128, activation=\"relu\")(dense1)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(dense2)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "functional_model.summary()\n",
    "functional_model.load_weights(\"model_w.h5\")\n",
    "functional_model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[metrics.CategoricalAccuracy(), metrics.Precision(), metrics.Recall()]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 591us/step - loss: 0.0768 - categorical_accuracy: 0.9778 - precision_1: 0.9789 - recall_1: 0.9762\n",
      "Accuracy:  0.9778000116348267\n",
      "Precision:  0.978941023349762\n",
      "Recall:  0.9761999845504761\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy_functional_eval, precision_functional_eval, recall_functional_eval) = functional_model.evaluate(testX, tf.one_hot(testY, depth=10), verbose=1)\n",
    "print(\"Accuracy: \", accuracy_functional_eval)\n",
    "print(\"Precision: \", precision_functional_eval)\n",
    "print(\"Recall: \", recall_functional_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn metrics (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 500us/step\n",
      "Accuracy:  0.9778\n",
      "Precision:  0.9778581534433096\n",
      "Recall:  0.9775777296255154\n"
     ]
    }
   ],
   "source": [
    "preds_functional = functional_model.predict(testX)\n",
    "accuracy_functional = accuracy_score(testY, preds_functional.argmax(axis=1))\n",
    "precision_functional, recall_functional, _, _ = precision_recall_fscore_support(\n",
    "    testY, preds_functional.argmax(axis=1), average='macro')\n",
    "print(\"Accuracy: \", accuracy_functional)\n",
    "print(\"Precision: \", precision_functional)\n",
    "print(\"Recall: \", recall_functional)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Raw predictions:  [[2.9017097e-10 9.9630810e-08 9.1427519e-06 8.2642044e-05 2.4783178e-09\n",
      "  1.3760470e-08 2.5339904e-12 9.9990022e-01 8.1127148e-08 7.8429593e-06]\n",
      " [2.0258680e-11 4.6203073e-07 9.9999869e-01 6.8475242e-07 2.3875413e-16\n",
      "  2.0451862e-08 9.4727164e-11 1.1061840e-08 9.8418937e-08 4.8029636e-12]\n",
      " [8.7542776e-07 9.9791926e-01 8.5040723e-05 5.1883439e-06 8.6449640e-05\n",
      "  2.7820242e-06 5.2900217e-05 1.4191855e-03 4.1309578e-04 1.5299325e-05]\n",
      " [9.9987257e-01 1.6904997e-07 9.9806144e-05 1.1384545e-07 5.2204527e-08\n",
      "  3.0985743e-07 4.4615067e-06 8.5699612e-06 2.8328417e-09 1.3971470e-05]\n",
      " [1.1878739e-08 2.2973106e-09 2.3022245e-08 1.4703636e-08 9.9937505e-01\n",
      "  2.6422565e-06 1.1956548e-08 3.0697925e-06 2.3329465e-06 6.1690516e-04]]\n",
      "Sum predictions:  [[5.        5.        5.000009  5.0000825 5.        5.        5.\n",
      "  5.9999003 5.        5.0000076]\n",
      " [5.        5.0000005 5.9999986 5.0000005 5.        5.        5.\n",
      "  5.        5.        5.       ]\n",
      " [5.000001  5.997919  5.000085  5.0000052 5.0000863 5.000003  5.000053\n",
      "  5.001419  5.000413  5.0000153]\n",
      " [5.9998727 5.        5.0000997 5.        5.        5.0000005 5.0000043\n",
      "  5.0000086 5.        5.000014 ]\n",
      " [5.        5.        5.        5.        5.999375  5.000003  5.\n",
      "  5.000003  5.0000024 5.000617 ]]\n",
      "Raw predictions (indices):  tf.Tensor([7 2 1 0 4], shape=(5,), dtype=int64)\n",
      "Sum predictions (indices):  tf.Tensor([7 2 1 0 4], shape=(5,), dtype=int64)\n",
      "Test Y values:  [7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "scalar = layers.Input(shape=(), dtype=tf.float32)\n",
    "batch = layers.Input(shape=(28, 28), dtype=tf.float32)\n",
    "preds_raw = sequential_model(batch)\n",
    "preds_sum = layers.Add()([preds_raw, scalar])\n",
    "model = keras.Model(inputs=[scalar, batch], outputs=[preds_raw, preds_sum])\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[metrics.SparseCategoricalAccuracy()])\n",
    "raw_preds, sum_preds = model.predict(\n",
    "    [tf.constant([5.0]*5, dtype=tf.float32), testX[:5]])\n",
    "print(\"Raw predictions: \", raw_preds)\n",
    "print(\"Sum predictions: \", sum_preds)\n",
    "print(\"Raw predictions (indices): \", tf.argmax(raw_preds, axis=1))\n",
    "print(\"Sum predictions (indices): \", tf.argmax(sum_preds, axis=1))\n",
    "print(\"Test Y values: \", testY[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
